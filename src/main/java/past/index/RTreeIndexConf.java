package past.index;

import java.io.Serializable;
import java.util.ArrayList;
import java.util.List;

import scala.Tuple2;
import past.storage.Timeseries;

import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.function.PairFunction;

public class RTreeIndexConf implements Serializable {

	private static final long serialVersionUID = -5579609120512826257L;

	/**
	 * Constant value used by the mappers.
	 */
	public static final int SINGLE_VALUE = 1;
	
	/**
	 * The dataset is timeseries. Example if the dimension is 4:
	 * {28, 920, 983, 220}
	 * {49, 853, 122, 7453}
	 * 
	 * The RDD is represented as a pair :
	 * pointer -> vector
	 */
    JavaPairRDD<String, int[]> dataset;

	/**
	 * Dimension of the vectors in the dataset.
	 */
	private int dataDimension;
	
	/**
	 * The data will be partitioned by this number of partitions.
	 */
	private int numberOfPartitions;

	/**
	 * Relative quantity of timeseries vectors to sample for the estimation of the splitting points.
	 */
	private double sampleFraction;
	
	/**
	 * The branch factor of the R-Tree (=number of childs of each node).
	 */
	private int rTreeBranchFactor;
	
	/**
	 * Default constructor, using a given RDD.
	 * 
	 * @param dataset the dataset to index.
	 * @param dataDimension dimension of each vector (=timeseries)
	 * @param nbPartitions number of partitions to use
	 * @param sampleFraction quantity of vectors to sample for the splitting points estimation
	 * @param rTreeBranchFactor number of children of each node in the RTree
	 */
	public RTreeIndexConf(JavaPairRDD<String, int[]> dataset, int dataDimension, 
			int nbPartitions, double sampleFraction, int rTreeBranchFactor) {
		
		if (dataset == null || dataDimension < 1 || nbPartitions < 1 || 
				sampleFraction < 0 || rTreeBranchFactor < 1) {
			throw new IllegalArgumentException();
		}
		
		this.dataset = dataset;
		this.dataDimension = dataDimension;
		this.numberOfPartitions = nbPartitions;
		this.sampleFraction = sampleFraction;
		this.rTreeBranchFactor = rTreeBranchFactor;
	}
	
	/**
	 * Default constructor, using the PAST's storage API.
	 * Length of the two arrays must be the same.
	 * 
	 * See the more general constructor for parameters explanations.
	 * @param jsc the spark context object
	 * @param timeseries array of timeseries from database
	 * @param columnNames corresponding column name of each timeseries
	 */
	public RTreeIndexConf(JavaSparkContext jsc, Timeseries[] timeseries, String[] columnNames, 
			int dataDimension, int nbPartitions, double sampleFraction, int rTreeBranchFactor) {
		this(generateRDD(jsc, timeseries, columnNames), 
				dataDimension, nbPartitions, sampleFraction, rTreeBranchFactor);
	}
	
	/**
	 * Constructor using default values, using a given RDD.
     * See the more general constructor for parameters explanations.
	 */
	public RTreeIndexConf(JavaPairRDD<String, int[]> dataset, int dataDimension) {
		this(dataset, dataDimension, 5, 0.03, 30);
	}
	
	/**
	 * Constructor using default values, using the PAST's storage API.
	 * Length of the two arrays must be the same.
	 * See the more general constructor for parameters explanations.
	 */
	public RTreeIndexConf(JavaSparkContext jsc, Timeseries[] timeseries, String[] columnNames, int dataDimension) {
		this(generateRDD(jsc, timeseries, columnNames), dataDimension);
	}

	/**
	 * WARNING : as for now, this method does not work, the RDD has to be correctly generated by the storage
     *
     * @param timeseries array of timeseries from database
     * @param columnNames corresponding column name of each timeseries
	 */
	@SuppressWarnings("unchecked")
	private static JavaPairRDD<String, int[]> generateRDD(JavaSparkContext jsc, Timeseries[] timeseries, String[] columnNames) {
		if (jsc == null || timeseries == null || columnNames == null || 
				timeseries.length != columnNames.length || timeseries.length < 1) {
			throw new IllegalArgumentException();
		}
		
    	List<JavaPairRDD<String, int[]>> rdds = new ArrayList<JavaPairRDD<String, int[]>>();
		scala.reflect.ClassTag<Integer> tag = scala.reflect.ClassTag$.MODULE$.apply(Integer.class);

		for (int i = 0 ; i < timeseries.length ; i++) {
			JavaRDD<Integer> rdd = //TODO : ident null?? NOPE-->has to be added by someone
					JavaRDD.fromRDD(timeseries[i].getRDDatFiles(jsc.sc(), columnNames[i], null, tag), tag);
			
			final String tsName = timeseries[i].name();
			JavaPairRDD<String, int[]> transformedRdd = 
					rdd.glom().map(new PairFunction<List<Integer>, String, int[]>() {
						private static final long serialVersionUID = 1L;

						@Override
						public Tuple2<String, int[]> call(List<Integer> vector) throws Exception {
							int[] array = new int[vector.size()];
							for (int i = 0 ; i < vector.size() ; i++) {
								array[i] = vector.get(i);
							}
							return new Tuple2<>(tsName, array);
						}
					});
			
			rdds.add(transformedRdd);
		}
    	
    	return jsc.union(rdds.toArray(new JavaPairRDD[0]));
    }

	public int getDataDimension() {
		return dataDimension;
	}
	
	public int getNumberOfPartitions() {
		return numberOfPartitions;
	}
	
	public double getSampleFraction() {
		return sampleFraction;
	}
	
	public int getRTreeBranchFactor() {
		return rTreeBranchFactor;
	}

	public JavaPairRDD<String, int[]> getDataset() {
		return this.dataset;
	}
}
